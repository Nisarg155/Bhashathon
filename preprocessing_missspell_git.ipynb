{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5ZOAbKbbfVN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a_bSCJzbqDr",
        "outputId": "4eba8155-5d31-4a7b-8649-7843b43a2877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJv_qJC5b1v5",
        "outputId": "c5032e65-6b3b-46e0-b3a2-adfb35119177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing complete. Check match.src and match.trg for matched lines, and diff.src and diff.trg for mismatched lines.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def get_first_word(line):\n",
        "    # Remove leading special characters\n",
        "    line = re.sub(r'^\\W+', '', line)\n",
        "    # Extract the first word\n",
        "    words = line.split()\n",
        "    return words[0] if words else ''\n",
        "\n",
        "def process_files(src_file, trg_file, match_src, match_trg, diff_src, diff_trg):\n",
        "    with open(src_file, 'r', encoding='utf-8') as src, \\\n",
        "         open(trg_file, 'r', encoding='utf-8') as trg:\n",
        "        src_lines = src.readlines()\n",
        "        trg_lines = trg.readlines()\n",
        "\n",
        "    matched_src = []\n",
        "    matched_trg = []\n",
        "    diff_src_lines = []\n",
        "    diff_trg_lines = []\n",
        "\n",
        "    for src_line, trg_line in zip(src_lines, trg_lines):\n",
        "        src_word = get_first_word(src_line)\n",
        "        trg_word = get_first_word(trg_line)\n",
        "\n",
        "        if src_word != trg_word:\n",
        "            diff_src_lines.append(src_line)\n",
        "            diff_trg_lines.append(trg_line)\n",
        "        else:\n",
        "            matched_src.append(src_line)\n",
        "            matched_trg.append(trg_line)\n",
        "\n",
        "    with open(match_src, 'w', encoding='utf-8') as ms, \\\n",
        "         open(match_trg, 'w', encoding='utf-8') as mt:\n",
        "        ms.writelines(matched_src)\n",
        "        mt.writelines(matched_trg)\n",
        "\n",
        "    with open(diff_src, 'w', encoding='utf-8') as ds, \\\n",
        "         open(diff_trg, 'w', encoding='utf-8') as dt:\n",
        "        ds.writelines(diff_src_lines)\n",
        "        dt.writelines(diff_trg_lines)\n",
        "\n",
        "# File paths\n",
        "source_file = \"/content/drive/MyDrive/github-typos.train.src\"\n",
        "target_file = \"/content/drive/MyDrive/github-typos.train.tgt\"\n",
        "match_source_file = \"/content/drive/MyDrive/match.src\"\n",
        "match_target_file = \"/content/drive/MyDrive/match.trg\"\n",
        "diff_source_file = \"/content/drive/MyDrive/diff.src\"\n",
        "diff_target_file = \"/content/drive/MyDrive/diff.trg\"\n",
        "\n",
        "process_files(source_file, target_file, match_source_file, match_target_file, diff_source_file, diff_target_file)\n",
        "print(\"Processing complete. Check match.src and match.trg for matched lines, and diff.src and diff.trg for mismatched lines.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def create_mispelled_csv(src_file, trg_file, output_csv):\n",
        "    with open(src_file, 'r', encoding='utf-8') as src, \\\n",
        "         open(trg_file, 'r', encoding='utf-8') as trg:\n",
        "        # Read lines from both files\n",
        "        src_lines = src.readlines()\n",
        "        trg_lines = trg.readlines()\n",
        "    \n",
        "    # Ensure the lengths of both files match\n",
        "    if len(src_lines) != len(trg_lines):\n",
        "        print(\"Warning: Source and target files have different lengths!\")\n",
        "    \n",
        "    # Create a list of tuples with (mispelled_sentence, correct_sentence)\n",
        "    data = []\n",
        "    for src_line, trg_line in zip(src_lines, trg_lines):\n",
        "        # Strip extra spaces or newline characters\n",
        "        src_line = src_line.strip()\n",
        "        trg_line = trg_line.strip()\n",
        "        data.append((src_line, trg_line))\n",
        "    \n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data, columns=[\"Mispelled_Sentence\", \"Correct_Sentence\"])\n",
        "    \n",
        "    # Save to CSV\n",
        "    df.to_csv(output_csv, index=False, encoding='utf-8')\n",
        "    print(f\"âœ… CSV file '{output_csv}' has been created!\")\n",
        "\n",
        "# File paths\n",
        "src_file = \"/content/drive/MyDrive/match(3).src\"\n",
        "trg_file = \"/content/drive/MyDrive/match(3).trg\"\n",
        "output_csv = \"/content/drive/MyDrive/mispelled_sentences_git.csv\"\n",
        "\n",
        "# Call the function to generate the CSV\n",
        "create_mispelled_csv(src_file, trg_file, output_csv)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_content_after_sentence(input_file, output_file, sentence):\n",
        "    try:\n",
        "        with open(input_file, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "        \n",
        "        index = content.find(sentence)\n",
        "        \n",
        "        if index != -1:\n",
        "            content = content[:index + len(sentence)]\n",
        "        \n",
        "        with open(output_file, 'w', encoding='utf-8') as file:\n",
        "            file.write(content)\n",
        "        \n",
        "        print(\"Content modified and saved successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Input file not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "input_filename = \"/content/drive/MyDrive/match.trg\"  # Replace with your actual input file name\n",
        "output_filename = \"/content/drive/MyDrive/diff_match.trg\"  # Replace with your desired output file name\n",
        "sentence_to_keep = \"Illustrate the operation of HEAP-EXTRACT-MAX on the heap A = [15, 13, 9, 5, 12, 8, 7, 4, 0, 6, 2, 1].\"\n",
        "\n",
        "remove_content_after_sentence(input_filename, output_filename, sentence_to_keep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_content_at_sentence(input_file, output_file1, output_file2, sentence):\n",
        "    try:\n",
        "        with open(input_file, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "\n",
        "        index = content.find(sentence)\n",
        "\n",
        "        if index != -1:\n",
        "            before_content = content[:index + len(sentence)]  # Keep this part in output_file1\n",
        "            after_content = content[index + len(sentence):]  # Store this part in output_file2\n",
        "\n",
        "            with open(output_file1, 'w', encoding='utf-8') as file:\n",
        "                file.write(before_content)\n",
        "\n",
        "            with open(output_file2, 'w', encoding='utf-8') as file:\n",
        "                file.write(after_content)\n",
        "\n",
        "            print(\"Content successfully split into two files.\")\n",
        "        else:\n",
        "            print(\"Sentence not found in the file.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Input file not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "input_filename = \"/content/drive/MyDrive/match.trg\"  # Your input file\n",
        "output_filename1 = \"/content/drive/MyDrive/math_before_sentence.trg\"  # File to store content before and including the sentence\n",
        "output_filename2 = \"/content/drive/MyDrive/match_after_sentence.trg\"  # File to store content after the sentence\n",
        "\n",
        "sentence_to_split = \"Illustrate the operation of HEAP-EXTRACT-MAX on the heap A = [15, 13, 9, 5, 12, 8, 7, 4, 0, 6, 2, 1].\"\n",
        "\n",
        "split_content_at_sentence(input_filename, output_filename1, output_filename2, sentence_to_split)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def split_content_at_sentence(input_file, output_file1, output_file2, sentence):\n",
        "    try:\n",
        "        with open(input_file, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "\n",
        "        index = content.find(sentence)\n",
        "\n",
        "        if index != -1:\n",
        "            before_content = content[:index + len(sentence)]  # Keep this part in output_file1\n",
        "            after_content = content[index + len(sentence):]  # Store this part in output_file2\n",
        "\n",
        "            with open(output_file1, 'w', encoding='utf-8') as file:\n",
        "                file.write(before_content)\n",
        "\n",
        "            with open(output_file2, 'w', encoding='utf-8') as file:\n",
        "                file.write(after_content)\n",
        "\n",
        "            print(\"Content successfully split into two files.\")\n",
        "        else:\n",
        "            print(\"Sentence not found in the file.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Input file not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "input_filename = \"/content/drive/MyDrive/match.src\"  # Your input file\n",
        "output_filename1 = \"/content/drive/MyDrive/math_before_sentence.src\"  # File to store content before and including the sentence\n",
        "output_filename2 = \"/content/drive/MyDrive/match_after_sentence.src\"  # File to store content after the sentence\n",
        "\n",
        "sentence_to_split = \"Illustrate the operation of HEAP-EXTRACT-MAX on the heap A = [15, 13, 9, 5, 12, 8, 7, 4, 0, 6, 2, 1].\"\n",
        "\n",
        "split_content_at_sentence(input_filename, output_filename1, output_filename2, sentence_to_split)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def create_misspelling_dataset(src_file, trg_file, output_csv, remaining_src_file, remaining_trg_file, limit=57100):\n",
        "    try:\n",
        "        with open(src_file, 'r', encoding='utf-8') as src, open(trg_file, 'r', encoding='utf-8') as trg:\n",
        "            src_lines = src.readlines()\n",
        "            trg_lines = trg.readlines()\n",
        "\n",
        "        # Split data: First 57,100 lines for CSV, the rest for new files\n",
        "        csv_src_lines = src_lines[:limit]\n",
        "        csv_trg_lines = trg_lines[:limit]\n",
        "        remaining_src_lines = src_lines[limit:]\n",
        "        remaining_trg_lines = trg_lines[limit:]\n",
        "\n",
        "        # Write selected lines to CSV\n",
        "        with open(output_csv, 'w', newline='', encoding='utf-8') as csv_file:\n",
        "            writer = csv.writer(csv_file)\n",
        "            writer.writerow([\"misspelled\", \"corrected\"])  # Header row\n",
        "            for src_line, trg_line in zip(csv_src_lines, csv_trg_lines):\n",
        "                writer.writerow([src_line.strip(), trg_line.strip()])  # Write one pair per row\n",
        "\n",
        "        # Write remaining lines to new separate files\n",
        "        with open(remaining_src_file, 'w', encoding='utf-8') as src, open(remaining_trg_file, 'w', encoding='utf-8') as trg:\n",
        "            src.writelines(remaining_src_lines)\n",
        "            trg.writelines(remaining_trg_lines)\n",
        "\n",
        "        print(f\"CSV file '{output_csv}' created with {limit} lines.\")\n",
        "        print(f\"Remaining {len(remaining_src_lines)} lines saved in '{remaining_src_file}' and '{remaining_trg_file}'.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"One or both input files not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "src_filename = \"/content/drive/MyDrive/match_after_sentence.src\"  \n",
        "trg_filename = \"/content/drive/MyDrive/match_after_sentence.trg\"  \n",
        "output_csv_filename = \"/content/drive/MyDrive/miss_spelling_dataset_next.csv\"  \n",
        "remaining_src_filename = \"/content/drive/MyDrive/remaining_data.src\"  # New file for remaining src lines\n",
        "remaining_trg_filename = \"/content/drive/MyDrive/remaining_data.trg\"  # New file for remaining trg lines\n",
        "\n",
        "create_misspelling_dataset(src_filename, trg_filename, output_csv_filename, remaining_src_filename, remaining_trg_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def merge_csv_files(file1, file2, output_file):\n",
        "    try:\n",
        "        total_rows = 0  # Counter for total rows\n",
        "        \n",
        "        with open(output_file, 'w', newline='', encoding='utf-8') as out_csv:\n",
        "            writer = csv.writer(out_csv)\n",
        "\n",
        "            # Read first file\n",
        "            with open(file1, 'r', encoding='utf-8') as f1:\n",
        "                reader1 = csv.reader(f1)\n",
        "                header1 = next(reader1)  # Read header\n",
        "                writer.writerow(header1)  # Write header to output file\n",
        "                \n",
        "                for row in reader1:\n",
        "                    writer.writerow(row)\n",
        "                    total_rows += 1  # Count rows\n",
        "\n",
        "            # Read second file (skip header)\n",
        "            with open(file2, 'r', encoding='utf-8') as f2:\n",
        "                reader2 = csv.reader(f2)\n",
        "                next(reader2)  # Skip header\n",
        "                \n",
        "                for row in reader2:\n",
        "                    writer.writerow(row)\n",
        "                    total_rows += 1  # Count rows\n",
        "\n",
        "        print(f\"CSV files merged successfully into '{output_file}'.\")\n",
        "        print(f\"Total number of rows in merged file (excluding header): {total_rows}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"One or both input files not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "file1 = \"/content/drive/MyDrive/mispelled_sentences_git.csv\"\n",
        "file2 = \"/content/drive/MyDrive/miss_spelling_dataset_next.csv\"\n",
        "output_file = \"/content/drive/MyDrive/merged_miss_spelling_dataset.csv\"\n",
        "\n",
        "merge_csv_files(file1, file2, output_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "847 data remaining_src_filename and remaining_trg_filename"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
